<body>
 <br/>
 <br/>
 <br/>
 <br/>
 <br/>
 <div id="body">
  <div id="navigate">
   <iframe align="left" frameborder="0" height="2000" scrolling="no" src="contents.html" width="25%">
    (Sorry, your browser does not support inline frames.)
   </iframe>
  </div>
  <div id="main">
   <img align="left" alt="Rolling Die" src="RollingDie.gif"/>
   <img align="right" alt="Rolling Die" src="RollingDie.gif"/>
   <h1 class="title">
    Probabilistic Fallacy
   </h1>
   <p class="noindent">
    <strong class="section">
     Taxonomy:
    </strong>
    <a href="logifall.html" target="_top">
     Logical Fallacy
    </a>
    &gt;
    <a href="formfall.html" target="_top">
     Formal Fallacy
    </a>
    &gt; Probabilistic Fallacy
    <p class="noindent">
     <strong class="section">
      Subfallacies:
     </strong>
     <ul>
      <li>
       <a href="baserate.html" target="_top">
        The Base Rate Fallacy
       </a>
       <li>
        <a href="conjunct.html" target="_top">
         The Conjunction Fallacy
        </a>
        <li>
         <a href="gamblers.html" target="_top">
          The Gambler's Fallacy
         </a>
         <li>
          <a href="hothandf.html" target="_top">
           The Hot Hand Fallacy
          </a>
          <li>
           <a href="multcomp.html" target="_top">
            The Multiple Comparisons Fallacy
           </a>
          </li>
         </li>
        </li>
       </li>
      </li>
     </ul>
     <h3 class="section">
      Exposition:
     </h3>
     <p>
      A probabilistic
      <a href="glossary.html#Argument" target="_top" title="A unit of reasoning.">
       argument
      </a>
      is one which concludes that something has some probability based upon information about probabilities given in its
      <a href="glossary.html#Premiss" target="_top" title="Part of an argument that gives evidence.">
       premiss
      </a>
      es.  Such an argument is in
      <a href="glossary.html#Valid" target="_top" title="Necessarily truth-preserving">
       valid
      </a>
      when the inference from the premisses to the
      <a href="glossary.html#Conclusion" target="_top" title="The part of an argument for which evidence is given.">
       conclusion
      </a>
      violates the laws of probability.  Probabilistic fallacies are formal ones because they involve reasoning which violates the formal rules of probability theory.  Thus, understanding probabilistic fallacies requires a knowledge of probability theory.
      <h3 class="section">
       A Short Introduction to Probability Theory:
      </h3>
      <p>
       In the following laws of probability, the probability of a proposition,
       <strong>
        s
       </strong>
       , is represented as: P(
       <strong>
        s
       </strong>
       ).
       <ol>
        <li>
         P(
         <strong>
          s
         </strong>
         ) ≥ 0.
         <p>
          The probability of a proposition is a real number greater than or equal to 0.  In other words, zero is the lowest probability, and there are no negative probabilities.  It follows from axioms 2 and 3, below, that P(
          <strong>
           s
          </strong>
          ) ≤ 1, which means that a probability is a real number between 0 and 1.
          <li>
           P(
           <strong>
            t
           </strong>
           ) = 1, if
           <strong>
            t
           </strong>
           is a
           <a href="glossary.html#Tautology" target="_top" title="A truth-functionally compound proposition that is true on all truth-value assignments.">
            tautology
           </a>
           .
           <p>
            The probability of any tautology is equal to 1.  This is because a tautology is necessarily true, and 1 is the value in probability theory that represents truth.
            <sup>
             <a href="#Note1">
              1
             </a>
            </sup>
            <li>
             If
             <strong>
              s
             </strong>
             and
             <strong>
              t
             </strong>
             are
             <a href="glossary.html#ContraryProps" title="Cannot both be true.">
              contrary
             </a>
             <a href="glossary.html#Proposition" title="A sentence that is true or false.">
              proposition
             </a>
             s, then P(
             <strong>
              s
             </strong>
             or
             <strong>
              t
             </strong>
             ) = P(
             <strong>
              s
             </strong>
             ) + P(
             <strong>
              t
             </strong>
             ).
             <sup>
              <a href="#Note2">
               2
              </a>
             </sup>
             <p>
              The probability of a
              <a href="glossary.html#Disjunction" target="_top" title="A proposition of the 'either-or' form.">
               disjunction
              </a>
              of contrary propositions is equal to the sum of the probabilities of its
              <a href="glossary.html#Disjunct" target="_top" title="A component of a disjunction.">
               disjunct
              </a>
              s, where a "disjunction" is a proposition of the "
              <strong>
               s
              </strong>
              or
              <strong>
               t
              </strong>
              " form and
              <strong>
               s
              </strong>
              and
              <strong>
               t
              </strong>
              are its "disjuncts".
              <sup>
               <a href="#Note3">
                3
               </a>
              </sup>
              <p class="noindent">
               A conditional probability is the probability of a proposition on the condition that some proposition is true.  For instance, the probability of getting lung cancer is an unconditional probability, whereas the probability of getting lung cancer given that you smoke cigarettes is a conditional probability, as is the probability of getting lung cancer if you don't smoke.  Each of these probabilities is distinct:  The probability of getting lung cancer if you smoke is higher than the unconditional probability of getting lung cancer, which is higher than the probability of getting lung cancer if you don't smoke.  The conditional probability of
               <strong>
                s
               </strong>
               given
               <strong>
                t
               </strong>
               is represented as: P(
               <strong>
                s
               </strong>
               |
               <strong>
                t
               </strong>
               ).
               <p class="noindent">
                There is one final axiom that governs conditional probabilities:
                <li>
                 P(
                 <strong>
                  s
                 </strong>
                 |
                 <strong>
                  t
                 </strong>
                 ) = P(
                 <strong>
                  s
                 </strong>
                 &amp;
                 <strong>
                  t
                 </strong>
                 )/P(
                 <strong>
                  t
                 </strong>
                 ), if P(
                 <strong>
                  t
                 </strong>
                 ) ≠ 0.
                 <sup>
                  <a href="#Note4">
                   4
                  </a>
                 </sup>
                 <p>
                  The conditional probability of
                  <strong>
                   s
                  </strong>
                  given
                  <strong>
                   t
                  </strong>
                  is equal to the probability of the
                  <a href="glossary.html#Conjunction" target="_top" title="A proposition of the 'both-and' form.">
                   conjunction
                  </a>
                  of
                  <strong>
                   s
                  </strong>
                  and
                  <strong>
                   t
                  </strong>
                  divided by the probability of
                  <strong>
                   t
                  </strong>
                  , where P(
                  <strong>
                   s
                  </strong>
                  &amp;
                  <strong>
                   t
                  </strong>
                  ) is the probability that the conjunction of
                  <strong>
                   s
                  </strong>
                  and
                  <strong>
                   t
                  </strong>
                  is true, where a "conjunction" is a proposition of the "
                  <strong>
                   s
                  </strong>
                  and
                  <strong>
                   t
                  </strong>
                  " form.
                 </p>
                </li>
               </p>
              </p>
             </p>
            </li>
           </p>
          </li>
         </p>
        </li>
       </ol>
       <p>
        The above laws are logically sufficient to prove every fact within probability theory, including a theorem that is important for explaining probabilistic fallacies:
        <p>
         <a name="BayesTheorem">
          <strong>
           Bayes' Theorem:
          </strong>
         </a>
         P(
         <strong>
          s | t
         </strong>
         ) =
         <p class="indent">
          P(
          <strong>
           t | s
          </strong>
          )P(
          <strong>
           s
          </strong>
          ) /
[P(
          <strong>
           t | s
          </strong>
          )P(
          <strong>
           s
          </strong>
          ) + P(
          <strong>
           t | not-s
          </strong>
          )P(
          <strong>
           not-s
          </strong>
          )].
          <sup>
           <a href="#Note5">
            5
           </a>
          </sup>
          <p>
           <strong>
            Proof:
           </strong>
           From axiom 4, we know that P(
           <strong>
            s
           </strong>
           |
           <strong>
            t
           </strong>
           ) = P(
           <strong>
            s
           </strong>
           &amp;
           <strong>
            t
           </strong>
           )/P(
           <strong>
            t
           </strong>
           ).  Since "
           <strong>
            s
           </strong>
           &amp;
           <strong>
            t
           </strong>
           " is logically equivalent to "
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           ", P(
           <strong>
            s
           </strong>
           &amp;
           <strong>
            t
           </strong>
           ) = P(
           <strong>
            t
           </strong>
           |
           <strong>
            s
           </strong>
           )P(
           <strong>
            s
           </strong>
           ), again by axiom 4, which is the numerator of the fraction in Bayes' Theorem.
           <sup>
            <a href="#Note6">
             6
            </a>
           </sup>
           To get the denominator of the fraction, "
           <strong>
            t
           </strong>
           " is logically equivalent to "(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           ) or (
           <strong>
            t
           </strong>
           &amp;
           <strong>
            not-s
           </strong>
           )", so P(
           <strong>
            t
           </strong>
           ) = P[(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           ) or (
           <strong>
            t
           </strong>
           &amp;
           <strong>
            not-s
           </strong>
           )].  Since "(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           )" and "(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            not-s
           </strong>
           )" are contraries, it follows that P[(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           ) or (
           <strong>
            t
           </strong>
           &amp;
           <strong>
            not-s
           </strong>
           )] = P(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            s
           </strong>
           ) + P(
           <strong>
            t
           </strong>
           &amp;
           <strong>
            not-s
           </strong>
           ), by axiom 3.  By applying axiom 4 again, we have that P(
           <strong>
            t
           </strong>
           ) = P(
           <strong>
            t | s
           </strong>
           )P(
           <strong>
            s
           </strong>
           ) + P(
           <strong>
            t | not-s
           </strong>
           )P(
           <strong>
            not-s
           </strong>
           ), which is the denominator.
           <h3 class="section">
            Exposure:
           </h3>
           <p>
            Mistakes in reasoning about probabilities are typically not treated as formal fallacies by logicians.  This is presumably because logicians usually do not make a study of probability theory, and the mathematicians who do don't generally study logical fallacies.  However, in recent decades, psychologists have discovered through observation and experiment that people are prone to make certain types of error when reasoning about probabilities.  As a consequence, there is now much more empirical evidence for the existence of certain fallacies about probabilities than there is for most traditional fallacies.  Again, logicians are often unaware of the existence of this evidence, and they usually do not discuss it in works on logical fallacies.  It is about time that logicians broadened their intellectual horizons and began to take note of discoveries in the psychology of reasoning.
            <sup>
             <a href="#Note7">
              7
             </a>
            </sup>
            <p>
             <strong class="section">
              Resource:
             </strong>
             Amir D. Aczel,
             <cite>
              Chance: A Guide to Gambling, Love, the Stock Market, &amp; Just About Everything Else
             </cite>
             (2004).  About as untechnical an introduction to probability theory as you will find.
             <p>
              <strong>
               Notes:
              </strong>
              <ol>
               <li>
                <a name="Note1">
                 As you might suspect
                </a>
                , 0 represents falsehood, so the probability of a
                <a href="glossary.html#Contradiction" target="_top" title="A truth-functionally compound proposition that is false on all truth-value assignments.">
                 contradiction
                </a>
                is equal to 0, as can easily be proven from this axiom taken together with the next one.
                <li>
                 <a name="Note2">
                  This is sometimes called "the addition law" or "the addition rule".
                 </a>
                 <li>
                  <a name="Note3">
                   It follows from the axioms that for any two propositions
                  </a>
                  ,
                  <strong>
                   s
                  </strong>
                  and
                  <strong>
                   t
                  </strong>
                  , contrary or not, that: P(
                  <strong>
                   s
                  </strong>
                  or
                  <strong>
                   t
                  </strong>
                  ) = P(
                  <strong>
                   s
                  </strong>
                  ) + P(
                  <strong>
                   t
                  </strong>
                  ) - P(
                  <strong>
                   s
                  </strong>
                  &amp;
                  <strong>
                   t
                  </strong>
                  ).
                  <li>
                   <a name="Note4">
                    Equivalently
                   </a>
                   , P(
                   <strong>
                    s
                   </strong>
                   &amp;
                   <strong>
                    t
                   </strong>
                   ) = P(
                   <strong>
                    s
                   </strong>
                   |
                   <strong>
                    t
                   </strong>
                   )P(
                   <strong>
                    t
                   </strong>
                   ).  This is often called "the multiplication rule" or "the multiplication law".  If
                   <strong>
                    s
                   </strong>
                   and
                   <strong>
                    t
                   </strong>
                   are probabilistically independent―that is, if P(
                   <strong>
                    s
                   </strong>
                   |
                   <strong>
                    t
                   </strong>
                   ) = P(
                   <strong>
                    s
                   </strong>
                   ) and P(
                   <strong>
                    t
                   </strong>
                   |
                   <strong>
                    s
                   </strong>
                   ) = P(
                   <strong>
                    t
                   </strong>
                   )―then the rule simplifies to: P(
                   <strong>
                    s
                   </strong>
                   &amp;
                   <strong>
                    t
                   </strong>
                   ) = P(
                   <strong>
                    s
                   </strong>
                   )P(
                   <strong>
                    t
                   </strong>
                   ).
                   <li>
                    <a name="Note5">
                     There are several forms of Bayes' Theorem
                    </a>
                    ; this is not the simplest form―see the next note―but it is the most useful one for my purposes.
                    <li>
                     <a name="Note6">
                      At this point in the proof
                     </a>
                     , we have proved that P(
                     <strong>
                      s | t
                     </strong>
                     ) = P(
                     <strong>
                      t | s
                     </strong>
                     )P(
                     <strong>
                      s
                     </strong>
                     ) / P(
                     <strong>
                      t
                     </strong>
                     ), which is the simplest version of Bayes' Theorem.  The rest of the proof is devoted to showing that P(
                     <strong>
                      t
                     </strong>
                     ) = P(
                     <strong>
                      t | s
                     </strong>
                     )P(
                     <strong>
                      s
                     </strong>
                     ) + P(
                     <strong>
                      t | not-s
                     </strong>
                     )P(
                     <strong>
                      not-s
                     </strong>
                     ).
                     <li>
                      <a name="Note7">
                       The
                       <em>
                        locus classicus
                       </em>
                       is
                      </a>
                      : Daniel Kahneman, Paul Slovic &amp; Amos Tversky, editors,
                      <cite>
                       Judgment Under Uncertainty: Heuristics and Biases
                      </cite>
                      (1985).
                     </li>
                    </li>
                   </li>
                  </li>
                 </li>
                </li>
               </li>
              </ol>
              <p>
               <strong class="section">
                Acknowledgment:
               </strong>
               Thanks to Emil William Kirkegaard for pointing out a problem, which has subsequently been fixed, with the wording of the informal description of the first axiom of probability.
              </p>
             </p>
            </p>
           </p>
          </p>
         </p>
        </p>
       </p>
      </p>
     </p>
    </p>
   </p>
  </div>
  <div id="sidebar">
   <script type="text/javascript">
    <!--
google_ad_client = "ca-pub-5792838462578692";
/* Contents2 */
google_ad_slot = "8652921947";
google_ad_width = 336;
google_ad_height = 280;
//-->
   </script>
   <script src="http://pagead2.googlesyndication.com/pagead/show_ads.js" type="text/javascript">
   </script>
   <h3>
    <a href="whatarff.html#AdPolicy" target="_top">
     Advertise in
     <cite>
      The Fallacy Files
     </cite>
    </a>
   </h3>
   <p>
    <cite>
     The Fallacy Files
    </cite>
    does not endorse products or services advertised here.  Ads makes it possible to continue as a free site.  Thank you for your support!
    <hr/>
    <h3>
     Search
     <cite>
      The Fallacy Files
     </cite>
     :
    </h3>
    <!--------------------- SiteSearch Google Begins --------------------->
    <form action="http://www.google.com/custom" method="get" target="_top">
     <table align="center" bgcolor="FFFFEO" border="0">
      <tr>
       <td align="center" height="32" nowrap="nowrap" valign="top">
       </td>
       <td nowrap="nowrap">
        <input name="domains" type="hidden" value="www.fallacyfiles.org"/>
        <input maxlength="255" name="q" size="26" type="text" value=""/>
       </td>
      </tr>
      <tr>
       <td>
       </td>
       <td nowrap="nowrap">
        <table>
         <tr>
          <td>
           <input name="sitesearch" type="radio" value=""/>
           <font color="#000000" size="-1">
            Web
           </font>
          </td>
          <td>
           <input checked="checked" name="sitesearch" type="radio" value="www.fallacyfiles.org"/>
           <font color="#000000" size="-1">
            www.fallacyfiles.org
           </font>
          </td>
         </tr>
        </table>
        <input name="sa" type="submit" value="Google Search"/>
        <input name="client" type="hidden" value="pub-5792838462578692"/>
        <input name="forid" type="hidden" value="1"/>
        <input name="ie" type="hidden" value="ISO-8859-1"/>
        <input name="oe" type="hidden" value="ISO-8859-1"/>
        <input name="safe" type="hidden" value="active"/>
        <input name="cof" type="hidden" value="GALT:#009999;GL:1;DIV:#009900;VLC:006699;AH:center;BGC:FFFFCC;LBGC:009999;ALC:000000;LC:000000;T:009999;GFNT:006699;GIMP:006699;LH:0;LW:0;L:http://www.fallacyfiles.org/FileFolder.gif;S:http://www.fallacyfiles.org;FORID:1;"/>
        <input name="hl" type="hidden" value="en"/>
       </td>
      </tr>
     </table>
    </form>
    <!---------------------- SiteSearch Google Ends ---------------------->
    <hr/>
    <h3>
     <a href="whatarff.html#Support" target="_top">
      Support
      <cite>
       The Fallacy Files
      </cite>
     </a>
    </h3>
    <form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank">
     <input name="cmd" type="hidden" value="_s-xclick"/>
     <input name="hosted_button_id" type="hidden" value="2254872"/>
     <input alt="Donate to The Fallacy Files" border="0" name="submit" src="https://www.paypal.com/en_US/i/btn/btn_donate_LG.gif" type="image"/>
     <img alt="" border="0" height="1" src="https://www.paypal.com/en_US/i/scr/pixel.gif" width="1"/>
    </form>
    <hr/>
    <h3>
     Resources
    </h3>
    <p>
     <iframe frameborder="0" marginheight="0" marginwidth="0" scrolling="no" src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=US&amp;source=ac&amp;ref=tf_til&amp;ad_type=product_link&amp;tracking_id=thefallacyfil-20&amp;marketplace=amazon®ion=US&amp;placement=B0034KZZZI&amp;asins=B0034KZZZI&amp;linkId=0b86aa7e1928e8b71972bc570056ea01&amp;show_border=false&amp;link_opens_in_new_window=true&amp;price_color=006666&amp;title_color=006699&amp;bg_color=ffffff" style="width:120px;height:240px;">
     </iframe>
     <p>
      <iframe frameborder="0" marginheight="0" marginwidth="0" scrolling="no" src="//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&amp;OneJS=1&amp;Operation=GetAdHtml&amp;MarketPlace=US&amp;source=ac&amp;ref=tf_til&amp;ad_type=product_link&amp;tracking_id=thefallacyfil-20&amp;marketplace=amazon®ion=US&amp;placement=B073RNVSTZ&amp;asins=B073RNVSTZ&amp;linkId=c7b92f0cd1b718a504fdfc5a2ed58456&amp;show_border=false&amp;link_opens_in_new_window=true&amp;price_color=006666&amp;title_color=006699&amp;bg_color=ffffff" style="width:120px;height:240px;">
      </iframe>
      <hr/>
      <h3>
       <a href="mailto:fallacist@fallacyfiles.org">
        Email the Fallacist
       </a>
      </h3>
      <h5>
       © Copyright 2001-2017: Gary N. Curtis
      </h5>
      <h6>
       Permission is granted for non-commercial use and replication of this material for educational purposes, provided that appropriate notice is included of both its authorship and copyrighted status.
      </h6>
     </p>
    </p>
   </p>
  </div>
  <div id="footer">
   <iframe border="0" frameborder="0" height="90" marginwidth="0" scrolling="no" src="http://rcm-na.amazon-adsystem.com/e/cm?t=thefallacyfil-20&amp;o=1&amp;p=48&amp;l=ur1&amp;category=books&amp;banner=1WV938XZP3V21MG4E2R2&amp;f=ifr&amp;linkID=AMVWDSLMXLYUPYOX" style="border:none;" width="728">
   </iframe>
   <script type="text/javascript">
    <!--
google_ad_client = "ca-pub-5792838462578692";
/* Index */
google_ad_slot = "8304009879";
google_ad_width = 728;
google_ad_height = 90;
//-->
   </script>
   <script src="http://pagead2.googlesyndication.com/pagead/show_ads.js" type="text/javascript">
   </script>
  </div>
 </div>
</body>
